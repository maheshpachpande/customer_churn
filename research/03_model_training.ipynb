{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pachp\\\\Desktop\\\\projects\\\\customer_churn\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pachp\\\\Desktop\\\\projects\\\\customer_churn'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    model_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_churn.constants import *\n",
    "from customer_churn.utils.common_utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_path=config.model_path\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from box.exceptions import BoxValueError\n",
    "from customer_churn import logging\n",
    "from customer_churn.utils.common_utils import save_object, evaluate_model\n",
    "from imblearn.combine import SMOTEENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def initiate_model_trainer(self, train_arr, test_arr):\n",
    "        try:\n",
    "            logging.info(\"Split the data into Train and Test...........\")\n",
    "            X_train, y_train, X_test, y_test = (\n",
    "                train_arr[:,:-1],\n",
    "                train_arr[:,-1],\n",
    "                test_arr[:,:-1],\n",
    "                test_arr[:,-1]\n",
    "            )\n",
    "\n",
    "            sme = SMOTEENN(random_state=42)\n",
    "            x_res, y_res = sme.fit_resample(X_train, y_train)\n",
    "\n",
    "            params={\n",
    "                # 'RandomForestClassifier':{\n",
    "                #      'criterion':['gini', 'entropy', 'log_loss'],                 \n",
    "                #      'max_features':['auto','sqrt','log2',None],\n",
    "                #      'max_depth':[int(x) for x in np.linspace(10, 1000, 10)],\n",
    "                #      'min_samples_split':[1,3,4,5,7,8,9,10],\n",
    "                #      'n_estimators': #[8,16,32,64,128,256,512,1024,2048] ,\n",
    "                #             [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
    "                #      'min_samples_leaf':[1,2,3,4,5,6,7,8]\n",
    "                #  },\n",
    "                # 'GradientBoostingClassifier':{\n",
    "                #     'loss':['log_loss', 'exponential'],\n",
    "                #     'learning_rate':[.1,.01,.05,.001],\n",
    "                #     'n_estimators': [8,16,32,64,128,256,512,1024],\n",
    "                #     'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                #     'criterion':['squared_error', 'friedman_mse'],\n",
    "                #     'max_features':['auto','sqrt','log2'],\n",
    "                #     },\n",
    "                # 'LogisticRegression':{\n",
    "                #     'max_iter':[100, 200, 300]\n",
    "                #     },\n",
    "                # 'XGBClassifier':{\n",
    "                #     'eval_metric':['auc','logloss','error'],\n",
    "                #     'eta':[0.01,0.02,0.05, 0.08, 0.1, 0.15, 0.19],\n",
    "                #     'max_depth':[3,4,5,6,7,8,9,10],\n",
    "                #     'subsample':[0.5,0.6,0.7,0.8,0.9]\n",
    "                #     },\n",
    "                # 'CatBoostClassifier':{},\n",
    "                # 'AdaBoostClassifier':{                    \n",
    "                #     'n_estimators': [8,16,32,64,128,256,512,1024]\n",
    "                #     },\n",
    "                'KNeighborsClassifier':{\n",
    "                    # 'n_neighbors':[1,2,3,4,5,6,7,8,9],\n",
    "                    'weights':['uniform','distance'],\n",
    "                    # 'algorithm':['auto', 'ball_tree','kd_tree']\n",
    "                    }\n",
    "                \n",
    "            }\n",
    "\n",
    "            models={\n",
    "                    # 'LogisticRegression':LogisticRegression(),\n",
    "                    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "            #         'XGBClassifier':XGBClassifier(),\n",
    "            #         'CatBoostClassifier':CatBoostClassifier(verbose=True),\n",
    "            #         'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "            #         'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "            #         'RandomForestClassifier':RandomForestClassifier()\n",
    "              }\n",
    "\n",
    "\n",
    "            model_report:dict=evaluate_model(X_train=x_res, y_train=y_res, X_test=X_test, \n",
    "                                             y_test=y_test, models=models, param=params)\n",
    "            \n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "            best_model = models[best_model_name]\n",
    "\n",
    "            if best_model_score < 0.6:\n",
    "                raise ValueError(\"No Best Model Found.....\")\n",
    "            \n",
    "            \n",
    "            logging.info(\"Best found model on both train and test dataset\")\n",
    "\n",
    "            save_object(\n",
    "                file_path=self.config.model_path,\n",
    "                obj=best_model\n",
    "            )\n",
    "\n",
    "            predicted = best_model.predict(X_test)\n",
    "\n",
    "            accuracy_score1 = accuracy_score(y_test, predicted)\n",
    "\n",
    "            return accuracy_score1\n",
    "\n",
    "        \n",
    "        except BoxValueError:\n",
    "            raise ValueError(\"Error occured at initiate model training.....\")\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('artifacts/df.csv')\n",
    "train_arr = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('artifacts/df1.csv')\n",
    "test_arr = np.array(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-14 00:47:16,016: INFO: common_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-14 00:47:16,022: INFO: common_utils: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-14 00:47:16,026: INFO: common_utils: created directory at: artifacts]\n",
      "[2024-03-14 00:47:16,031: INFO: common_utils: created directory at: artifacts/model_trainer]\n",
      "[2024-03-14 00:47:16,031: INFO: 2742073462: Split the data into Train and Test...........]\n",
      "[2024-03-14 00:47:32,340: INFO: 2742073462: Best found model on both train and test dataset]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()   \n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.initiate_model_trainer(train_arr,test_arr)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5634, 1161)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('artifacts/df.csv')\n",
    "train_arr = np.array(df)\n",
    "train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
